{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab&wordlen.pkl', 'rb') as f:\n",
    "    vocab,max_word_len = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dim=300\n",
    "char_embedding_dim=200\n",
    "q_words=50\n",
    "c_words=400\n",
    "embedding_dim = word_embedding_dim+char_embedding_dim\n",
    "batch_size=64\n",
    "model_encoder_layers=3\n",
    "no_of_chars = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.insert(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print \"Loading Glove Model\"\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print \"Done.\",len(model),\" words loaded!\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = loadGloveModel(\"glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(inputs, output_size, bias = None, activation = None, kernel_size = 1, name = \"conv\"):\n",
    "    with tf.variable_scope(name):\n",
    "        def_shape=4\n",
    "        if len(inputs.shape)==3:\n",
    "            inputs = tf.expand_dims(inputs,axis=1)\n",
    "            def_shape=3\n",
    "        shapes = inputs.shape.as_list()\n",
    "        filter_shape = [1,kernel_size,shapes[-1],output_size]\n",
    "        bias_shape = [1,1,1,output_size]\n",
    "        strides = [1,1,1,1]\n",
    "        kernel_ = tf.get_variable(\"kernel_\",\n",
    "                        filter_shape,\n",
    "                        dtype = tf.float32,\n",
    "                        regularizer= tf.contrib.layers.l2_regularizer(scale = 3e-7),\n",
    "                        initializer = tf.contrib.layers.xavier_initializer())\n",
    "        outputs = tf.nn.conv2d(inputs, kernel_, strides, \"VALID\")\n",
    "        if bias:\n",
    "            outputs += tf.get_variable(\"bias_\",\n",
    "                        bias_shape,\n",
    "                        regularizer= tf.contrib.layers.l2_regularizer(scale = 3e-7),\n",
    "                        initializer = tf.zeros_initializer())\n",
    "        if def_shape==3:\n",
    "            outputs = tf.squeeze(outputs,axis=1)\n",
    "        if activation is not None:\n",
    "            return activation(outputs)\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthconv(x, kernel_size, output_filters, scope_name):\n",
    "    with tf.variable_scope(scope_name):\n",
    "        shapes = x.shape.as_list()\n",
    "        depthwise_filter = tf.get_variable(\"depthwise_filter\",\n",
    "                                        (kernel_size[0], kernel_size[1], shapes[-1], 1),\n",
    "                                        dtype = tf.float32,\n",
    "                                        regularizer= tf.contrib.layers.l2_regularizer(scale = 3e-7),\n",
    "                                        initializer = tf.contrib.layers.xavier_initializer())\n",
    "        pointwise_filter = tf.get_variable(\"pointwise_filter\",\n",
    "                                        (1,1,shapes[-1],output_filters),\n",
    "                                        dtype = tf.float32,\n",
    "                                        regularizer=tf.contrib.layers.l2_regularizer(scale = 3e-7),\n",
    "                                        initializer = tf.contrib.layers.xavier_initializer())\n",
    "        outputs = tf.nn.separable_conv2d(x,\n",
    "                                        depthwise_filter,\n",
    "                                        pointwise_filter,\n",
    "                                        strides = (1,1,1,1),\n",
    "                                        padding = \"SAME\")\n",
    "        b = tf.get_variable(\"bias\",\n",
    "                outputs.shape[-1],\n",
    "                regularizer=tf.contrib.layers.l2_regularizer(scale = 3e-7),\n",
    "                initializer = tf.zeros_initializer())\n",
    "        outputs += b\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_attention(q,k,v,scope=\"dot_product_attention\"):\n",
    "    \"\"\"\n",
    "    q: a Tensor with shape [batch, heads, length_q, depth_k]\n",
    "    k: a Tensor with shape [batch, heads, length_kv, depth_k]\n",
    "    v: a Tensor with shape [batch, heads, length_kv, depth_v]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        # [batch, num_heads, query_length, memory_length]\n",
    "        logits = tf.matmul(q, k, transpose_b=True)\n",
    "        logits = logits/(k.shape.as_list()[-1]**0.5)\n",
    "        weights = tf.nn.softmax(logits, name=\"attention_weights\")\n",
    "        # dropping out the attention links for each of the heads\n",
    "        return tf.matmul(weights, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_attention(queries, units, num_heads, memory = None, scope = \"Multi_Head_Attention\"):\n",
    "    with tf.variable_scope(scope):\n",
    "        # Self attention\n",
    "        if memory is None:\n",
    "            memory = queries\n",
    "        memory = conv(memory, 2 * units, name = \"memory_projection\")\n",
    "        query = conv(queries, units, name = \"query_projection\")\n",
    "        qshapes = query.shape.as_list()\n",
    "        Q = tf.reshape(query, [qshapes[0],qshapes[1],num_heads,-1])\n",
    "        Q = tf.transpose(Q,[0,2,1,3])\n",
    "\n",
    "        mshapes = memory.shape.as_list()\n",
    "        M = tf.reshape(memory, [qshapes[0],qshapes[1],num_heads*2,-1])\n",
    "        M = tf.transpose(M,[0,2,1,3])\n",
    "        K, V = tf.split(M,2,axis=1)\n",
    "\n",
    "        x = dot_product_attention(Q,K,V)\n",
    "        \n",
    "        shapes = x.shape.as_list()\n",
    "        return tf.reshape(tf.transpose(x,[0,2,1,3]),[shapes[0],shapes[2],-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderblock(x, kernel_size, output_filters, num_conv_layers, scope_name, num_blocks=1, reuse=False):\n",
    "    with tf.variable_scope(scope_name, reuse=reuse):\n",
    "        x = tf.expand_dims(x,axis=1)\n",
    "        x = conv(x,output_filters,name=\"conv0\")\n",
    "        for _ in range(num_blocks):\n",
    "            with tf.variable_scope(\"Block\"+str(_)):\n",
    "                for i in range(num_conv_layers):\n",
    "                    if len(x.shape.as_list())==3:\n",
    "                        x=tf.expand_dims(x,axis=1)\n",
    "                    y = tf.contrib.layers.layer_norm(x)\n",
    "                    y = depthconv(y, kernel_size, output_filters, 'dconv'+str(i))\n",
    "\n",
    "                    x = x+y\n",
    "                x = tf.squeeze(x, axis=1)\n",
    "                x = tf.contrib.layers.layer_norm(x)\n",
    "                x = multihead_attention(x,output_filters,8)\n",
    "                x = tf.contrib.layers.layer_norm(x)\n",
    "                x = conv(x,output_filters,True,activation=tf.nn.relu,name=\"FFN\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q=tf.placeholder(tf.float32,[batch_size,q_words,embedding_dim])\n",
    "# print encoderblock(q,(7,1),128,4,\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highway(x, size = None, activation = None, num_layers = 2, scope = \"highway\"):\n",
    "    with tf.variable_scope(scope):\n",
    "        if size is None:\n",
    "            size = x.shape.as_list()[-1]\n",
    "        else:\n",
    "            x = conv(x, size, name = \"input_projection\")\n",
    "        for i in range(num_layers):\n",
    "            T = conv(x, size, bias = True, activation = tf.sigmoid,\n",
    "                     name = \"gate_%d\"%i)\n",
    "            H = conv(x, size, bias = True, activation = activation,\n",
    "                     name = \"activation_%d\"%i)\n",
    "            x = H * T + x * (1.0 - T)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk = tf.get_variable(\"unk\",(word_embedding_dim),dtype = tf.float32,\n",
    "                                        regularizer= tf.contrib.layers.l2_regularizer(scale = 3e-7),\n",
    "                                        initializer = tf.contrib.layers.xavier_initializer())\n",
    "char_emb = tf.get_variable(\"char_emb\",(no_of_chars,char_embedding_dim),dtype = tf.float32,\n",
    "                                        regularizer= tf.contrib.layers.l2_regularizer(scale = 3e-7),\n",
    "                                        initializer = tf.contrib.layers.xavier_initializer())\n",
    "question_word = tf.placeholder(tf.float32,[batch_size,q_words,word_embedding_dim])\n",
    "question_char = tf.placeholder(tf.int32,[batch_size,q_words,None])\n",
    "context_word = tf.placeholder(tf.float32,[batch_size,c_words,word_embedding_dim])\n",
    "context_char = tf.placeholder(tf.int32,[batch_size,c_words,None])\n",
    "start_ans = tf.placeholder(tf.int32,[batch_size])\n",
    "end_ans = tf.placeholder(tf.int32,[batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_char = tf.zeros([1,char_embedding_dim], tf.float32)\n",
    "char_emb = tf.concat([zero_char,char_emb],axis=0)\n",
    "print char_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_char = tf.nn.embedding_lookup(char_emb,question_char)\n",
    "print question_char\n",
    "context_char = tf.nn.embedding_lookup(char_emb,context_char)\n",
    "print context_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Input_Embedding_Layer\"):\n",
    "    question_char1 = conv(question_char,char_embedding_dim,kernel_size=5,name=\"q_char_conv0\")\n",
    "    question_char1 = tf.reduce_max(question_char1,axis=2)\n",
    "    question_emb = tf.concat([question_word,question_char1],axis=-1)\n",
    "    question_emb = highway(question_emb, scope=\"q_highway\")\n",
    "    print question_emb\n",
    "    \n",
    "    context_char1 = conv(context_char,char_embedding_dim,kernel_size=5,name=\"c_char_conv0\")\n",
    "    context_char1 = tf.reduce_max(context_char1,axis=2)\n",
    "    context_emb = tf.concat([context_word,context_char1],axis=-1)\n",
    "    context_emb = highway(context_emb, scope=\"c_highway\")\n",
    "    print context_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Embedding_encoding_layer\"):\n",
    "    question = encoderblock(question_emb, (1,7), 128, 4, \"q_encoder_block\")\n",
    "    print question\n",
    "\n",
    "    context = encoderblock(context_emb, (1,7), 128, 4, \"c_encoder_block\")\n",
    "    print context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Context-query_attention\"):\n",
    "    q = tf.tile(tf.expand_dims(question,axis=1),[1,c_words,1,1])\n",
    "    c = tf.tile(tf.expand_dims(context,axis=2),[1,1,q_words,1])\n",
    "    s = conv(tf.concat([q,c,tf.multiply(q,c)],axis=-1),1,name=\"similarity_matrix\")\n",
    "    s = tf.squeeze(s,axis=-1)\n",
    "    print s\n",
    "    s_ = tf.nn.softmax(s,axis=-1)\n",
    "    a = tf.matmul(s_,question)\n",
    "    print a\n",
    "    b = tf.matmul(s_, tf.matmul(tf.transpose(tf.nn.softmax(s,axis=1),[0,2,1]),context))\n",
    "    print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Model_encoder_layer\"):\n",
    "    enc_input = tf.concat([context,a,context*a,context*b],axis=-1)\n",
    "    print enc_input\n",
    "    enc_input = conv(enc_input,128,name=\"conv0\")\n",
    "    enc_input = encoderblock(enc_input, (1,7), 128, 2, \"encoder_layer\", 7)\n",
    "    print enc_input\n",
    "    output_list = [enc_input]\n",
    "    for i in range(model_encoder_layers-1):\n",
    "        temp = encoderblock(output_list[i], (1,7), 128, 2, \"encoder_layer\", 7, True)\n",
    "        print temp\n",
    "        output_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Output_Layer\"):\n",
    "    start_logits = tf.squeeze(conv(tf.concat([output_list[0], output_list[1]],axis = -1),1, bias = False, name = \"start_pointer\"),-1)\n",
    "    end_logits = tf.squeeze(conv(tf.concat([output_list[0], output_list[2]],axis = -1),1, bias = False, name = \"end_pointer\"), -1)\n",
    "    \n",
    "    logits1 = tf.nn.softmax(start_logits)\n",
    "    logits2 = tf.nn.softmax(end_logits)\n",
    "    print logits1\n",
    "    \n",
    "    start = tf.one_hot(start_ans,c_words)\n",
    "    end = tf.one_hot(end_ans,c_words)\n",
    "    print start\n",
    "    start = tf.log(tf.multiply(start,logits1))\n",
    "    end = tf.log(tf.multiply(end,logits2))\n",
    "    losses = -(tf.reduce_mean(start)+tf.reduce_mean(end))\n",
    "    print losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.001\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           1000, 0.99, staircase=True)\n",
    "# Passing global_step to minimize() will increment it at each step.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "minimize = optimizer.minimize(losses,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter( './logs/1/train ', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.json') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = loadGloveModel(\"GloVe/glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(l, word_limit):\n",
    "    temp_w = []\n",
    "    for q in l:\n",
    "        if q in model.keys():\n",
    "            temp_w.append(model[q])\n",
    "        else:\n",
    "            temp_w.append(sess.run(unk))\n",
    "    print len(temp_w)\n",
    "    temp_zeros = np.array([0 for _ in range(word_embedding_dim)])\n",
    "    if len(temp_w)<word_limit:\n",
    "        temp_w+=[temp_zeros for _ in range(word_limit-len(temp_w))]\n",
    "    return np.array(temp_w[:word_limit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_embedding(l, word_limit):\n",
    "    temp_c = []\n",
    "    for q in l:\n",
    "        word = []\n",
    "        for char in q:\n",
    "            word.append(vocab.index(char))\n",
    "        word+=[0 for _ in range(max_word_len-len(word))]\n",
    "        temp_c.append(word)\n",
    "    if len(temp_c)<word_limit:\n",
    "        temp_c+=[[0 for _ in range(max_word_len)] for _ in range(word_limit-len(temp_c))]\n",
    "    return np.array(temp_c[:word_limit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(ans_predicted, ans_actual):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    for gold_toks, pred_toks in zip(ans_actual, ans_predicted):\n",
    "        common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "        num_same = sum(common.values())\n",
    "        tp+=num_same\n",
    "        fp+=(len(pred_tokens)-num_same)\n",
    "        tn+=(len(gold_tokens)-num_same)\n",
    "    return tp,fp,tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_batches = int(len(train_data['data'])/batch_size)\n",
    "epoch = 60\n",
    "prev_f1=0\n",
    "cur_f1=0\n",
    "max_f1=0\n",
    "\n",
    "for i in range(epoch):\n",
    "    count=0\n",
    "    q_w = []\n",
    "    q_c = []\n",
    "    c_w = []\n",
    "    c_c = []\n",
    "    a_s = []\n",
    "    a_e = []\n",
    "    for t in train_data['data']:\n",
    "        if t['answer_start']!=-1:\n",
    "            q_w.append(get_word_embedding(t['question'],q_words))\n",
    "            q_c.append(get_char_embedding(t['question'],q_words))\n",
    "            c_w.append(get_word_embedding(t['context'],c_words))\n",
    "            c_c.append(get_char_embedding(t['context'],c_words))\n",
    "            a_s.append(t['answer_start'])\n",
    "            a_e.append(t['answer_end'])\n",
    "            count+=1\n",
    "        if count==batch_size:\n",
    "            feed_dict={question_word:np.array(q_w),\n",
    "                       question_char:np.array(q_c),\n",
    "                       context_word:np.array(c_w),\n",
    "                       context_char:np.array(c_c),\n",
    "                       start_ans:np.array(a_s),\n",
    "                       end_ans:np.array(a_e)}\n",
    "            sess.run(minimize,feed_dict)\n",
    "            count=0\n",
    "            q_w = []\n",
    "            q_c = []\n",
    "            c_w = []\n",
    "            c_c = []\n",
    "            a_s = []\n",
    "            a_e = []\n",
    "            break\n",
    "    print \"Epoch - \",str(i)\n",
    "    tp=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    ans_ac = []\n",
    "    ans_pred = []\n",
    "    count=0\n",
    "    q_w = []\n",
    "    q_c = []\n",
    "    c_w = []\n",
    "    c_c = []\n",
    "    for t in test_data['data']:\n",
    "        q_w.append(get_word_embedding(t['question'],q_words))\n",
    "        q_c.append(get_char_embedding(t['question'],q_words))\n",
    "        c_w.append(get_word_embedding(t['context'],c_words))\n",
    "        c_c.append(get_char_embedding(t['context'],c_words))\n",
    "        ans_ac.append(t['answer'])\n",
    "        count+=1\n",
    "        if count%batch_size==0:\n",
    "            feed_dict={question_word:np.array(q_w),\n",
    "                       question_char:np.array(q_c),\n",
    "                       context_word:np.array(c_w),\n",
    "                       context_char:np.array(c_c)}\n",
    "            ans_st = sess.run(tf.argmax(logits1),feed_dict)\n",
    "            ans_e = sess.run(tf.argmax(logits2),feed_dict)\n",
    "            for k in range(batch_size):\n",
    "                ans_pred.append(test_data['data'][count-batch_size+k]['context'][ans_st[k]:ans_e[k]])\n",
    "            x,y,z=compute_f1(ans_pred, ans_ac)\n",
    "            tp+=x\n",
    "            fp+=y\n",
    "            tn+=z\n",
    "    precision = 1.0 * tp / (tp+fp)\n",
    "    recall = 1.0 * tp / (tp+tn)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    print(\"F1 Score:\")+str(f1)\n",
    "    if f1>max_f1:\n",
    "        save_path = saver.save(sess, \"./saved_model/model.ckpt\")\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "        max_f1 = f1\n",
    "    else:\n",
    "        print \"Not Saved\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
